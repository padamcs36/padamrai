# SUMMARY

As a seasoned Data Engineer, I specialize in architecting and implementing scalable data pipelines using Python, PySpark, and ETL processes. My expertise spans managing big data ecosystems, including databases, Apache Kafka, and Apache Airflow, to ensure seamless data flow and real-time analytics. Additionally, I utilize Power BI for informative data visualization and reporting. With a strong foundation in complex data architectures, I excel at optimizing performance, ensuring data integrity, and delivering high-quality results across diverse platforms.

## EDUCATION
- B.E., CSE | Mehran UET (_2016 - 2020_)

## WORK EXPERIENCE
**Data Engineer @ Jeeny (_Sep 2023 - Present_)**
- Understand the data requirements, sources, types, formats, and document data lineage and business rules.
-	Extract required data from MongoDB using queries, ensuring secure transfer and compliance.
-	Transformed data using Pandas for smaller datasets and spark for large-scale processing.
-	Load transformed data into SQL Server staging tables, ensuring data consistency. Verify data integrity and accuracy
through validation checks. Transfer validated data from staging to production tables, ensuring minimal downtime.
-	Schedule and monitor the ETL process using Cronjobs for simple schedules or Apache Airflow for complex workflows.
-	Led the migration of ETL processes from Pandas to PySpark, achieving a 30% reduction in processing time. Upgraded Python
2 ETL scripts to Python 3, improving code readability and optimization.

